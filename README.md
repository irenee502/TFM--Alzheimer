# TFM--Alzheimer
Master麓s thesis  TFM - Detecci贸n Temprana de Deterioro Cognitivo Leve mediante Inteligencia Artificial

Este repositorio contiene todo el c贸digo, scripts y documentaci贸n utilizados en el Trabajo de Fin de M谩ster (TFM), cuyo objetivo es desarrollar un sistema de diagn贸stico temprano del **Deterioro Cognitivo Leve (DCL)** mediante modelos de **Machine Learning** y **Deep Learning** aplicados a datos cl铆nicos, neuropsicol贸gicos y de neuroimagen funcional (fMRI).

A continuaci贸n se describe brevemente el contenido de cada uno de los archivos y carpetas del repositorio:

1. `Descarga_DL.ipynb`

Notebook inicial que permite al usuario descargar los datos necesarios para ejecutar el resto del pipeline. Incluye rutas, estructuras y comprobaci贸n b谩sica de integridad de los archivos descargados.

2. `EDA_.ipynb` (Exploratory Data Analysis)

Este notebook contiene un an谩lisis exploratorio de los datos cl铆nicos y neuropsicol贸gicos. Se incluyen visualizaciones de distribuciones, an谩lisis de correlaciones, detecci贸n de valores at铆picos y primeras inferencias 煤tiles para orientar los modelos de ML.

---

3. `machine_learning.ipynb`

Aqu铆 se implementan y comparan diferentes algoritmos de Machine Learning (Random Forest, Gradient Boosting, SVM, etc.) aplicados a los datos tabulares. Incluye selecci贸n de caracter铆sticas, evaluaci贸n de m茅tricas como AUROC y precisi贸n, as铆 como validaci贸n cruzada.

---

4. `prep_dL.ipynb`

Notebook dedicado al preprocesamiento de los datos funcionales (fMRI) que se utilizar谩n en Deep Learning. Se realizan tareas como normalizaci贸n, segmentaci贸n, filtrado por tipo de tarea (por ejemplo, VentralVisual), y construcci贸n de datasets personalizados para PyTorch.

---

5. `EDA_DeepLearning.ipynb`

An谩lisis visual de las im谩genes funcionales. Incluye histogramas de intensidad, inspecci贸n de regiones cerebrales activadas, visualizaci贸n de ejemplos concretos y comprobaci贸n del equilibrio de clases y calidad de las muestras funcionales.

---

6. `deep_learning.ipynb`

Entrenamiento de modelos de Deep Learning con arquitecturas CNN, RNN y Transformers. Se exploran distintas configuraciones de hiperpar谩metros (dropout, learning rate, regularizaci贸n, etc.), t茅cnicas de optimizaci贸n (Adam, ReduceLROnPlateau) y estrategias de mejora como autocast y batch normalization. Tambi茅n se eval煤an modelos preentrenados mediante Transfer Learning.

---

7. `ensamblado_modelos.ipynb`

Este script combina los modelos entrenados (tanto de ML como de DL) mediante t茅cnicas de ensemble: **soft averaging**, **hard voting** y **stacking**. Se comparan los resultados y se selecciona la mejor combinaci贸n basada en m茅tricas como AUROC, accuracy y recall.

---

8. `interpretabilidad.ipynb`

Notebook dedicado a la interpretaci贸n de los modelos de Deep Learning mediante t茅cnicas como **Grad-CAM**, **Occlusion Sensitivity**, **LIME** y **SHAP**. Se analizan visualmente las zonas cerebrales que m谩s influyen en las decisiones del modelo y se comparan con el conocimiento cl铆nico existente.

---

Documentaci贸n adicional

* `TFM_vX.docx`: Documento oficial del Trabajo de Fin de M谩ster en formato Word, con resultados, figuras, interpretaciones y bibliograf铆a.
* `README.md`: Este archivo, que explica la estructura y prop贸sito del repositorio.

---

Requisitos y entorno

Se recomienda crear un entorno virtual con las siguientes librer铆as clave:

```bash
pip install -r requirements.txt
```

Incluye:

* `pandas`, `numpy`, `matplotlib`, `seaborn`
* `scikit-learn`, `shap`, `lime`
* `torch`, `torchvision`, `monai`
* `nibabel`, `nilearn`, `einops`, `ants`

---

Contribuciones y contacto

Este proyecto ha sido desarrollado como parte del TFM del M谩ster en Inteligencia Artificial. Para m谩s informaci贸n o colaboraci贸n, puedes contactar al autor a trav茅s de aqu铆.

